<!doctype html>
<html lang="en-us">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
    <title>Task 3: Extracting dishes from reviews - CS 598 Data Mining Capstone</title>
    <link href="https://bobopd.github.io/capstone/css/bootstrap.css" rel="stylesheet">
    <link href="https://bobopd.github.io/capstone/styling.css" rel="stylesheet">
    <link href="https://fonts.googleapis.com/css2?family=Montserrat:ital,wght@0,100;0,200;0,300;0,400;0,500;0,600;0,700;0,800;0,900;1,100;1,200;1,300;1,400;1,500;1,600;1,700;1,800;1,900&display=swap" rel="stylesheet">
  </head>
  <body>

<header class="text-center bg-dark pt-5 pb-5 col-12">
  
  <h1 class="text-white pt-4 pb-3">Task 3: Extracting dishes from reviews</h1>
  <p class="text-secondary">June 13, 2020</p>
  
</header>
<div class="container">
  <div class="row pt-5">
    <div class="col-12">
      <p>In this excercise I will attempt to extract dishes that belong to a cuisine from the user reviews. For example, from the Chinese restaurant reviews I will try to extract the names of chinese dishes like hakka noodles, kung pao chicken etc. The primary method I used for this task is phrase extraction from the reviews and then trying to rank the phrases based on the probability that they are dishes for the cuisine in question.</p>
<p>For this task we chose to analyse 3 cuisines: Chinese, French and Italian.</p>
<h2 id="preprocessing-steps">Preprocessing steps</h2>
<p>In order to do phrase extraction I decided to tokenise all the reviews for a cuisine into an array of sentences. Since I am just trying to detect dish names, the individual reviews themselves are not important. Also, dish names will never be spread across sentence boundaries so if I split by sentences its guaranteed to not lose any dishes. This also helps us deal with arbitrary artifacts in user reviews like multiple line breaks, bullet points, etc.</p>
<p>To tokenise the reviews into sentences I used the <em>sent_tokenise()</em> method in nltk. I tried both the Punkt tokeniser and the regular expression tokeniser. The Punkt sentence tokeniser performed suprisingly poorly. It would only separate two sentences if there was a space after the period. Consider the two sentences below:</p>
<ul>
<li>This is sentence 1. This is sentence 2.</li>
<li>This is sentence 2.This is sentence 2.</li>
</ul>
<p>The only difference between these two sentences is the space after the first period in the first example. Yet the Punkt tokeniser was only was to separate the 2 sentences in the first case. Since most of the reviews were not formatted well it performed really poorly. A lot of the reviews did not have a space after the periods and that resulted in some of the reviews being returned as is with no evidence of any tokenisation at all. Hence I used a simple regular expression tokeniser that would separate the sentences based on simple english punctuation symbols. I know that this has obvious limitations like Dr. John Doe would get broken up into two sentences but food reviews typically don&rsquo;t contain too many such cases and the regular expression tokeniser did work much better at separating the sentences when I looked at them myself.</p>
<p>So at the end of the preprocessing stage we have a set of 3 files, one for each cuisine, that contains the list of sentences from the reviews for that cuisine. <a href="/capstone/chinese.txt">You can see the output for chinese here</a>.</p>
<h2 id="phrase-extraction">Phrase extraction</h2>
<p>For phrase extraction I have used SegPhrase. Since that required the presence of a relatively small number of labelled examples I have labelled the chinese phrases for the first task. I intend to use these labels with SegPhrase. The max number of tokens/phrase was set to the default of 6. I ran SegPhrase for all 3 cuisines on the review sentences generated in the previous step using the chinese labels as the training set for the classfier. Below is the the top 25 phrases for each cuisine for analysis:</p>
<table>
<thead>
<tr>
<th>Chinese</th>
<th>Italian</th>
<th>French</th>
</tr>
</thead>
<tbody>
<tr>
<td>dim sum</td>
<td>zuppa toscana</td>
<td>foie gras</td>
</tr>
<tr>
<td>sweet and sour sauce</td>
<td>yukon gold</td>
<td>croque monsieur</td>
</tr>
<tr>
<td>fried rice</td>
<td>wedding reception</td>
<td>short ribs</td>
</tr>
<tr>
<td>sesame oil</td>
<td>vino bambino</td>
<td>sea bass</td>
</tr>
<tr>
<td>el topo</td>
<td>vin santo</td>
<td>pinot noir</td>
</tr>
<tr>
<td>kung pao chicken</td>
<td>villa dolce</td>
<td>los angeles</td>
</tr>
<tr>
<td>stir fried</td>
<td>video poker</td>
<td>coq au vin</td>
</tr>
<tr>
<td>soy sauce</td>
<td>united states</td>
<td>prix fixe</td>
</tr>
<tr>
<td>pork belly</td>
<td>tutti santi</td>
<td>iced tea</td>
</tr>
<tr>
<td>peking duck</td>
<td>treasure island</td>
<td>hash browns</td>
</tr>
<tr>
<td>noodle soup</td>
<td>timely manner</td>
<td>guy savoy</td>
</tr>
<tr>
<td>mongolian beef</td>
<td>sun prairie</td>
<td>sin city</td>
</tr>
<tr>
<td>iced tea</td>
<td>spring training</td>
<td>sea urchin</td>
</tr>
<tr>
<td>hot pot</td>
<td>slot machines</td>
<td>salted caramel</td>
</tr>
<tr>
<td>green onion</td>
<td>sierra nevada</td>
<td>quiche lorraine</td>
</tr>
<tr>
<td>egg rolls</td>
<td>sheeps milk</td>
<td>passion fruit</td>
</tr>
<tr>
<td>deep fried</td>
<td>scott conant</td>
<td>orange juice</td>
</tr>
<tr>
<td>crab puffs</td>
<td>saving grace</td>
<td>olive oil</td>
</tr>
<tr>
<td>crab puff</td>
<td>sauvignon blanc</td>
<td>marche bacchus</td>
</tr>
<tr>
<td>crab legs</td>
<td>san marzano</td>
<td>maple syrup</td>
</tr>
<tr>
<td>chow mein</td>
<td>san marco</td>
<td>john dory</td>
</tr>
<tr>
<td>brown sauce</td>
<td>san diego</td>
<td>heat lamps</td>
</tr>
<tr>
<td>black bean</td>
<td>salted caramel sundae</td>
<td>grand marnier</td>
</tr>
<tr>
<td>shangri la</td>
<td>salted caramel</td>
<td>eiffel tower</td>
</tr>
<tr>
<td>pea pods</td>
<td>queen creek</td>
<td>dress code</td>
</tr>
</tbody>
</table>
<hr>
<p>As you can immediately notice, the phrases for chinese are almost all dishes. The accuracy is is excellent. However, the italian and french phrases don&rsquo;t do so well. The phrases themselves are of really good quality but they are mostly not dish names. <strong>This points to overfitting</strong>, since we used the chinese labels to train the classfier it did really well on the chinese dishes but not so much for the other cuisines. In fact, a lot of the dishes in this list appeared in the labels and so the classifier had already seen them. In order to make sure that it was overfit I also created labels for the italian data and then re-ran SegPhrase on the Italian reviews with the italian labels. This is what I got:</p>
<table>
<thead>
<tr>
<th>Italian</th>
<th>Italian improved</th>
</tr>
</thead>
<tbody>
<tr>
<td>zuppa toscana</td>
<td>white wine</td>
</tr>
<tr>
<td>yukon gold</td>
<td>wolfgang puck</td>
</tr>
<tr>
<td>wedding reception</td>
<td>whipped cream</td>
</tr>
<tr>
<td>vino bambino</td>
<td>strip mall</td>
</tr>
<tr>
<td>vin santo</td>
<td>sea bass</td>
</tr>
<tr>
<td>villa dolce</td>
<td>san francisco</td>
</tr>
<tr>
<td>video poker</td>
<td>pinot noir</td>
</tr>
<tr>
<td>united states</td>
<td>pine nuts</td>
</tr>
<tr>
<td>tutti santi</td>
<td>parmigiano reggiano</td>
</tr>
<tr>
<td>treasure island</td>
<td>panna cotta</td>
</tr>
<tr>
<td>timely manner</td>
<td>osso bucco</td>
</tr>
<tr>
<td>sun prairie</td>
<td>olive oil</td>
</tr>
<tr>
<td>spring training</td>
<td>olive garden</td>
</tr>
<tr>
<td>slot machines</td>
<td>naked city</td>
</tr>
<tr>
<td>sierra nevada</td>
<td>mashed potatoes</td>
</tr>
<tr>
<td>sheeps milk</td>
<td>mario batali</td>
</tr>
<tr>
<td>scott conant</td>
<td>mamma mia</td>
</tr>
<tr>
<td>saving grace</td>
<td>iced tea</td>
</tr>
<tr>
<td>sauvignon blanc</td>
<td>humble pie</td>
</tr>
<tr>
<td>san marzano</td>
<td>hash browns</td>
</tr>
<tr>
<td>san marco</td>
<td>goat cheese</td>
</tr>
<tr>
<td>san diego</td>
<td>gluten free</td>
</tr>
<tr>
<td>salted caramel sundae</td>
<td>fra diavolo</td>
</tr>
<tr>
<td>salted caramel</td>
<td>foie gras</td>
</tr>
<tr>
<td>queen creek</td>
<td>filet mignon</td>
</tr>
</tbody>
</table>
<p><em>Note: The first column is the same as the first run while the second column contains the phrases obtained using the italian labels</em></p>
<p>As you can see, there is a marked improvement in the quality of the phrases. A lot of them now are actually dishes unlike the first time. This conclusively proves that the models are indeed overfitting the labels and the only way to extract dish names of cuisines from reviews through SegPhrase is to actually have good labels for dish names for each cuisines we are interested in.</p>

    </div>
  </div>
  <div class="row pt-5 pb-5">
    <div class="col-6 text-left">
    
      <a class="text-reset" href="https://bobopd.github.io/capstone/task2/">&lt; Task 2: Similarity of cuisines</a>
    
    </div>
    <div class="col-6 text-right">
    
      <a class="text-reset" href="https://bobopd.github.io/capstone/task4_5/">Task 4 and 5: Sentiment Analysis of dish reviews ></a>
    
    </div>
  </div>
</div>
<footer class="text-center bg-dark pt-5 col-12">
  <a href="https://bobopd.github.io/capstone/" class="text-muted">Home</a>
  
</footer>
</body>
</html>
