{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sklearn as sk\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import requests\n",
    "import sys\n",
    "import utils\n",
    "from nltk.stem.porter import PorterStemmer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation\n",
    "\n",
    "The first step is to convert my data into a form that will make it easier to train classifiers on. I start with the _hygiene.dat.additional_ file since its already in CSV format and the easiest to read. I have converted the categories into an n-hot encoded vector that becomes a part of my features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = pd.read_csv(\"./Hygiene/hygiene.dat.additional\", header=None, names=[\"categories\", \"pincode\", \"review_count\", \"rating\"])\n",
    "features[\"categories\"] = features[\"categories\"].map(eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Length: 546. Sample top 10: [1, 1, 1, 0, 0, 1, 1, 0, 0, 0]\n"
    }
   ],
   "source": [
    "#Reading the labels provided\n",
    "given_labels = []\n",
    "with open(\"./Hygiene/hygiene.dat.labels\", \"r\") as f:\n",
    "    for i in range(546):\n",
    "        given_labels.append(int(f.readline()))\n",
    "\n",
    "print(f\"Length: {len(given_labels)}. Sample top 10: {given_labels[:10]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Getting the list of unique categories\n",
    "categories = set()\n",
    "for c in features[\"categories\"]:\n",
    "    t = set(c)\n",
    "    categories = categories.union(t)\n",
    "categories.remove(\"Restaurants\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "       pincode  review_count    rating  Hawaiian  Breakfast & Brunch  \\\n0        98118             4  4.000000     False               False   \n1        98109            21  4.047619     False               False   \n2        98103            14  3.111111     False               False   \n3        98112            42  4.088889     False               False   \n4        98102            12  3.071429     False               False   \n...        ...           ...       ...       ...                 ...   \n13294    98104             1  3.000000     False               False   \n13295    98116            29  4.258065     False               False   \n13296    98104             1  4.000000     False               False   \n13297    98109             2  4.000000     False               False   \n13298    98108             2  3.000000     False               False   \n\n       Chicken Wings  Barbeque  Senegalese  Italian  Asian Fusion  ...  \\\n0              False     False       False    False         False  ...   \n1              False     False       False    False         False  ...   \n2              False     False       False    False         False  ...   \n3              False     False       False    False         False  ...   \n4              False     False       False    False         False  ...   \n...              ...       ...         ...      ...           ...  ...   \n13294          False     False       False    False         False  ...   \n13295          False     False       False    False         False  ...   \n13296          False     False       False    False         False  ...   \n13297          False     False       False    False         False  ...   \n13298          False     False       False    False         False  ...   \n\n       Cheesesteaks  Hot Pot  Shanghainese  American (New)  Latin American  \\\n0             False    False         False           False           False   \n1             False    False         False           False           False   \n2             False    False         False           False           False   \n3             False    False         False           False           False   \n4             False    False         False           False           False   \n...             ...      ...           ...             ...             ...   \n13294         False    False         False           False           False   \n13295         False    False         False           False           False   \n13296         False    False         False           False           False   \n13297         False    False         False           False           False   \n13298         False    False         False           False           False   \n\n       Gastropubs  Salvadoran  Fish & Chips  Szechuan  Lebanese  \n0           False       False         False     False     False  \n1           False       False         False     False     False  \n2           False       False         False     False     False  \n3           False       False         False     False     False  \n4           False       False         False     False     False  \n...           ...         ...           ...       ...       ...  \n13294       False       False         False     False     False  \n13295       False       False         False     False     False  \n13296       False       False         False     False     False  \n13297       False       False         False     False     False  \n13298       False       False         False     False     False  \n\n[13299 rows x 101 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>pincode</th>\n      <th>review_count</th>\n      <th>rating</th>\n      <th>Hawaiian</th>\n      <th>Breakfast &amp; Brunch</th>\n      <th>Chicken Wings</th>\n      <th>Barbeque</th>\n      <th>Senegalese</th>\n      <th>Italian</th>\n      <th>Asian Fusion</th>\n      <th>...</th>\n      <th>Cheesesteaks</th>\n      <th>Hot Pot</th>\n      <th>Shanghainese</th>\n      <th>American (New)</th>\n      <th>Latin American</th>\n      <th>Gastropubs</th>\n      <th>Salvadoran</th>\n      <th>Fish &amp; Chips</th>\n      <th>Szechuan</th>\n      <th>Lebanese</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>0</td>\n      <td>98118</td>\n      <td>4</td>\n      <td>4.000000</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>...</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <td>1</td>\n      <td>98109</td>\n      <td>21</td>\n      <td>4.047619</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>...</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>98103</td>\n      <td>14</td>\n      <td>3.111111</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>...</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>98112</td>\n      <td>42</td>\n      <td>4.088889</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>...</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>98102</td>\n      <td>12</td>\n      <td>3.071429</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>...</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <td>13294</td>\n      <td>98104</td>\n      <td>1</td>\n      <td>3.000000</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>...</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <td>13295</td>\n      <td>98116</td>\n      <td>29</td>\n      <td>4.258065</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>...</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <td>13296</td>\n      <td>98104</td>\n      <td>1</td>\n      <td>4.000000</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>...</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <td>13297</td>\n      <td>98109</td>\n      <td>2</td>\n      <td>4.000000</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>...</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <td>13298</td>\n      <td>98108</td>\n      <td>2</td>\n      <td>3.000000</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>...</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n    </tr>\n  </tbody>\n</table>\n<p>13299 rows Ã— 101 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "# n-hot encoding for categories\n",
    "for cat in categories:\n",
    "    features[cat] = cat in features[\"categories\"]\n",
    "\n",
    "#dropping the categories column since its not needed anymore\n",
    "features = features.drop(\"categories\", axis=1)\n",
    "features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Review Data\n",
    "\n",
    "The reviews could also potentially provide additional insights into the hygiene of a restaurant. Since we are only interested about hygiene we need to extract the parts of the reviews that talk about hygiene. It is also not necessary that all reviews talk about hygiene. Initially I plan to use a simple method of counting hygiene related words in the review and rely on the rating of the restaurant to indicate whether the hygiene was good or bad. I understand that the rating is not just for the hygiene but I am assuming that if the restaurant was not clean that would be the overiding factor for the reviewer and that will help me classify the negative ones. The positive ones are a little bit trickier. In order to get the words related to hygiene I used the thesaurus.com APIs to get the synonyms and antonyms of the word and treat them as seed words. _The thing to notice about this approach is that it would work as well for any other topic. If we substitute hygiene with service the code would not change at all._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "{'benefit',\n 'cleanliness',\n 'contamination',\n 'defilement',\n 'dirt',\n 'dirtiness',\n 'filth',\n 'filthiness',\n 'foulness',\n 'generosity',\n 'good will',\n 'griminess',\n 'grubbiness',\n 'honesty',\n 'hygiene',\n 'hygienics',\n 'impureness',\n 'impurity',\n 'morality',\n 'pollution',\n 'probity',\n 'purification',\n 'purity',\n 'regimen',\n 'sanitation',\n 'squalor',\n 'sterility',\n 'uncleanliness',\n 'uncleanness',\n 'unwholesomeness',\n 'wholesomeness'}"
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "hygiene_rel_words = utils.get_topic_words([\"hygiene\"])\n",
    "hygiene_rel_words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that er have got our list of seed words we need to stem them and for that we'll use the PorterStemmer implementation in nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "{'benefit',\n 'cleanli',\n 'contamin',\n 'defil',\n 'dirt',\n 'dirti',\n 'filth',\n 'filthi',\n 'foul',\n 'generos',\n 'good wil',\n 'grimi',\n 'grubbi',\n 'honesti',\n 'hygien',\n 'impur',\n 'moral',\n 'pollut',\n 'probiti',\n 'purif',\n 'puriti',\n 'regimen',\n 'sanit',\n 'squalor',\n 'steril',\n 'unclean',\n 'uncleanli',\n 'unwholesom',\n 'wholesom'}"
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "stemmer = PorterStemmer()\n",
    "hygiene_rel_words_stem = {stemmer.stem(s) for s in hygiene_rel_words}\n",
    "hygiene_rel_words_stem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now I'm going to simply count total occurrances of each of the stemmed words in the reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./Hygiene/hygiene.dat\", \"r\") as rv_file:\n",
    "    counts = []\n",
    "    for line in rv_file:\n",
    "        c = 0\n",
    "        for w in hygiene_rel_words_stem:\n",
    "            p = line.find(w)\n",
    "            while p != -1:\n",
    "                c = c + 1\n",
    "                p = line.find(w, p+1)\n",
    "        \n",
    "        counts.append(c)\n",
    "\n",
    "features[\"hygiene_word_count\"] = counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "(2187, 102)"
     },
     "metadata": {},
     "execution_count": 19
    }
   ],
   "source": [
    "(features[features[\"hygiene_word_count\"] != 0]).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like only 2187/12299 of the reviews seem to discuss hygiene related topics. Lets try training classifiers with this information and see what happens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic Decision Tree trained with given labels\n",
    "\n",
    "Now I will attempt to train a basic decision tree on the given labels using just these features as input. Not considering the review data yet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n                       max_features=None, max_leaf_nodes=None,\n                       min_impurity_decrease=0.0, min_impurity_split=None,\n                       min_samples_leaf=1, min_samples_split=2,\n                       min_weight_fraction_leaf=0.0, presort=False,\n                       random_state=None, splitter='best')"
     },
     "metadata": {},
     "execution_count": 20
    }
   ],
   "source": [
    "training_data = features[:546]\n",
    "labels = given_labels\n",
    "\n",
    "classifier = DecisionTreeClassifier()\n",
    "classifier.fit(training_data, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = classifier.predict(features[546:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Submission completed successfully!\n"
    }
   ],
   "source": [
    "utils.pred_save_submit_to_leaderboard(predictions, \"dt.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This method yielded a Precision of 0.5256 and a Recall of 0.5272. So it was barely above random. Clearly not a good result.\n",
    "\n",
    "# Boosted Decision tree\n",
    "\n",
    "This time we train a boosted tree on the same data and see if that does better. AdaBoost is the algorithm used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None, learning_rate=1.0,\n                   n_estimators=50, random_state=None)"
     },
     "metadata": {},
     "execution_count": 23
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "# by default this implementation uses a DecisionTreeClassifier with a max depth of 1. Since we have very few features I didn't want to increase the depth\n",
    "boost_clf = AdaBoostClassifier()\n",
    "boost_clf.fit(training_data, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Submission completed successfully!\n"
    }
   ],
   "source": [
    "utils.pred_save_submit_to_leaderboard(boost_clf.predict(features[546:]), \"adaboost.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This method yielded a Precision of 0.5544 and a Recall of 0.5573. So a small improvement is observed. Next lets also try a random forest. I don't expect the results to be better than AdaBoost since boosting actively tries to fix its mistakes for the subsequent classifiers but I do expect it to do better that a single decision tree.\n",
    "\n",
    "# Random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n                       max_depth=None, max_features='auto', max_leaf_nodes=None,\n                       min_impurity_decrease=0.0, min_impurity_split=None,\n                       min_samples_leaf=1, min_samples_split=2,\n                       min_weight_fraction_leaf=0.0, n_estimators=10,\n                       n_jobs=None, oob_score=False, random_state=None,\n                       verbose=0, warm_start=False)"
     },
     "metadata": {},
     "execution_count": 25
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf_clf = RandomForestClassifier()\n",
    "rf_clf.fit(training_data, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Submission completed successfully!\n"
    }
   ],
   "source": [
    "utils.pred_save_submit_to_leaderboard(rf_clf.predict(features[546:]), \"random_forest.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Precision: 0.5377, Recall: 0.5418. Exactly as expected, the values are better than a single decision tree but not as good as the boosted tree method_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training using unlabelled data\n",
    "\n",
    "Next lets use some of the methods that we learnt for training models when the amount of unlabelled data is much more than that of the labelled data. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}